{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Set 10: Machine learning for predicting recidivism\n",
        "\n",
        "As always...\n",
        "\n",
        "1. Make your own copy of this notebook by going to `File->Save a copy in Drive`. This will create your own copy of this notebook that you can run on Colab.\n",
        "\n",
        "2. Click on the title of the notebook, up above, and change it to `YourLastName_YourFirstName_DSP_PS8.ipynb`.\n",
        "\n",
        "3. Go to `Share` in the upper right corner. Where it says \"Add people, groups, and calendar events\", enter the following email addresses (the TAs and me): parkut@bc.edu, bisc@bc.edu, prudhome@bc.edu.\n",
        "\n"
      ],
      "metadata": {
        "id": "OW2Z-qArHDnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Enter your honor pledge here*\n",
        "\n",
        "\"This code is my own work. I did not share my code or look at the code of another student. I did not consult ChatGPT, CoPilot, or another large language model.\""
      ],
      "metadata": {
        "id": "wsb8_TFRclQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "In this problem set, you'll be working with a dataset used to try to predict recidivism, whether someone commits a crime after they are paroled from prison. This is a much larger dataset than the ones we've used to far, in terms of both features and samples, so there is a lot more room for experimentation.\n",
        "\n",
        "You will be building models to try to beat the majority class baseline. I've provided code to get you started, and you will use this notebook to build your models. You can do anything you like to the features, and you can use any classifier you like with any parameterization you like.\n",
        "\n",
        "In the hackathon you carved out a separate dev set from your training data. This time you will be doing k-fold cross validation on on your models. **I have provided three examples of how to do this**, but this is something that was demonstrated earlier. Review the prior sample code and the lecture notes for more deails about k-fold cross validation.\n",
        "\n",
        "## What to turn in\n",
        "When you have three models whose average accuracy is better than majority baseline, you will re-build those model on the *whole* dataset and use those models to predict the data in `test.csv`. When you submit this notebook, you will also submit these three prediction files, which you will call `submission.csv`, `submission2.csv` and `submission3.csv`. When the TAs grade your homework, they will report back your accuracy on this test dataset.\n",
        "\n",
        "I have provided code that shows you how to create these files and how to move the files to a location in your Google Drive. You will download and submit these files with your GitHub repo, and you will also share the folder you create with the TAs, just as you share your Colab notebook.\n",
        "\n",
        "**This notebook only needs to contain the code for creating the three final models -- first within the k-fold cross-validation setting and second in the full dataset setting. You must comment your code so that we know you know what you are doing.**\n",
        "\n",
        "**This problem set is due Thursday, May 2, at 11:59pm.** You have a 24-hour grace period. (I don't want to make any work actually due after the end of classes, but you may submit the problem set on Friday if you prefer.)"
      ],
      "metadata": {
        "id": "XnfO1R9ncddZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Get the data"
      ],
      "metadata": {
        "id": "dh9ID8dyKvwt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojWcbPYqUfGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4bf3986-0efb-4f96-e2e3-8d4222210d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-30 19:34:41--  https://raw.githubusercontent.com/CSCI1090-S24/ps10/main/data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1995686 (1.9M) [text/plain]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "\rdata.csv              0%[                    ]       0  --.-KB/s               \rdata.csv            100%[===================>]   1.90M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-04-30 19:34:41 (31.6 MB/s) - ‘data.csv’ saved [1995686/1995686]\n",
            "\n",
            "--2024-04-30 19:34:41--  https://raw.githubusercontent.com/CSCI1090-S24/ps10/main/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 220728 (216K) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>] 215.55K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-30 19:34:42 (8.24 MB/s) - ‘test.csv’ saved [220728/220728]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm data.csv\n",
        "!rm test.csv\n",
        "!wget https://raw.githubusercontent.com/CSCI1090-S24/ps10/main/data.csv\n",
        "!wget https://raw.githubusercontent.com/CSCI1090-S24/ps10/main/test.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "recidivism = pd.read_csv(\"data.csv\")\n",
        "\n",
        "test_data = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "1y6tez7gUhlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describe the dataset\n",
        "print(recidivism.describe())\n",
        "\n",
        "# print out the number of rows (samples)\n",
        "rows, columns = recidivism.shape\n",
        "print(rows)\n",
        "\n",
        "# print out the number of features (columns)\n",
        "print(columns)\n",
        "\n",
        "# print out first 10 rows\n",
        "recidivism.head(10)\n",
        "\n",
        "# print out all column labels\n",
        "recidivism.columns"
      ],
      "metadata": {
        "id": "vRibN_sYVIKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a2dd7e-e26c-4877-ee4d-69536c906966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 ID  Residence_PUMA  Supervision_Risk_Score_First  \\\n",
            "count   8190.000000     8190.000000                   8076.000000   \n",
            "mean   13304.850549       12.172894                      5.868995   \n",
            "std     7820.321672        7.151819                      2.381232   \n",
            "min        1.000000        1.000000                      1.000000   \n",
            "25%     6407.750000        6.000000                      4.000000   \n",
            "50%    13278.000000       12.000000                      6.000000   \n",
            "75%    20177.250000       18.000000                      8.000000   \n",
            "max    26758.000000       25.000000                     10.000000   \n",
            "\n",
            "        Dependents  Prior_Arrest_Episodes_Felony  Prior_Arrest_Episodes_Misd  \\\n",
            "count  8190.000000                   8190.000000                 8190.000000   \n",
            "mean      1.516239                      5.469109                    3.148474   \n",
            "std       1.220742                      3.187848                    2.278922   \n",
            "min       0.000000                      0.000000                    0.000000   \n",
            "25%       0.000000                      3.000000                    1.000000   \n",
            "50%       1.000000                      5.000000                    3.000000   \n",
            "75%       3.000000                      9.000000                    6.000000   \n",
            "max       3.000000                     10.000000                    6.000000   \n",
            "\n",
            "       Prior_Arrest_Episodes_Violent  Prior_Arrest_Episodes_Property  \\\n",
            "count                    8190.000000                     8190.000000   \n",
            "mean                        0.989621                        2.027717   \n",
            "std                         1.075267                        1.859542   \n",
            "min                         0.000000                        0.000000   \n",
            "25%                         0.000000                        0.000000   \n",
            "50%                         1.000000                        2.000000   \n",
            "75%                         2.000000                        4.000000   \n",
            "max                         3.000000                        5.000000   \n",
            "\n",
            "       Prior_Arrest_Episodes_Drug  Prior_Arrest_Episodes_PPViolationCharges  \\\n",
            "count                 8190.000000                               8190.000000   \n",
            "mean                     1.774969                                  2.121123   \n",
            "std                      1.705811                                  1.909538   \n",
            "min                      0.000000                                  0.000000   \n",
            "25%                      0.000000                                  0.000000   \n",
            "50%                      1.000000                                  2.000000   \n",
            "75%                      3.000000                                  4.000000   \n",
            "max                      5.000000                                  5.000000   \n",
            "\n",
            "       ...  Program_UnexcusedAbsences  Residence_Changes  \\\n",
            "count  ...                8190.000000        8190.000000   \n",
            "mean   ...                   0.419414           0.805617   \n",
            "std    ...                   0.936128           1.016324   \n",
            "min    ...                   0.000000           0.000000   \n",
            "25%    ...                   0.000000           0.000000   \n",
            "50%    ...                   0.000000           0.000000   \n",
            "75%    ...                   0.000000           1.000000   \n",
            "max    ...                   3.000000           3.000000   \n",
            "\n",
            "       Avg_Days_per_DrugTest  DrugTests_THC_Positive  \\\n",
            "count            6523.000000             6945.000000   \n",
            "mean               93.145498                0.051837   \n",
            "std               113.921699                0.119538   \n",
            "min                 2.788406                0.000000   \n",
            "25%                29.833333                0.000000   \n",
            "50%                56.333333                0.000000   \n",
            "75%               110.366667                0.055556   \n",
            "max              1088.500000                1.000000   \n",
            "\n",
            "       DrugTests_Cocaine_Positive  DrugTests_Meth_Positive  \\\n",
            "count                 6945.000000              6945.000000   \n",
            "mean                     0.012243                 0.010726   \n",
            "std                      0.058128                 0.052577   \n",
            "min                      0.000000                 0.000000   \n",
            "25%                      0.000000                 0.000000   \n",
            "50%                      0.000000                 0.000000   \n",
            "75%                      0.000000                 0.000000   \n",
            "max                      1.000000                 1.000000   \n",
            "\n",
            "       DrugTests_Other_Positive  Percent_Days_Employed  Jobs_Per_Year  \\\n",
            "count               6945.000000            7971.000000    7822.000000   \n",
            "mean                   0.006963               0.574181       0.842047   \n",
            "std                    0.038541               0.417229       0.823472   \n",
            "min                    0.000000               0.000000       0.000000   \n",
            "25%                    0.000000               0.000000       0.183060   \n",
            "50%                    0.000000               0.729592       0.711988   \n",
            "75%                    0.000000               0.999040       1.083507   \n",
            "max                    1.000000               1.000000       6.393873   \n",
            "\n",
            "       Recidivism_Arrest  \n",
            "count        8190.000000  \n",
            "mean            0.397680  \n",
            "std             0.489449  \n",
            "min             0.000000  \n",
            "25%             0.000000  \n",
            "50%             0.000000  \n",
            "75%             1.000000  \n",
            "max             1.000000  \n",
            "\n",
            "[8 rows x 26 columns]\n",
            "8190\n",
            "50\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Gender', 'Race', 'Age_at_Release', 'Residence_PUMA',\n",
              "       'Gang_Affiliated', 'Supervision_Risk_Score_First',\n",
              "       'Supervision_Level_First', 'Education_Level', 'Dependents',\n",
              "       'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony',\n",
              "       'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent',\n",
              "       'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug',\n",
              "       'Prior_Arrest_Episodes_PPViolationCharges',\n",
              "       'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges',\n",
              "       'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd',\n",
              "       'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop',\n",
              "       'Prior_Conviction_Episodes_Drug',\n",
              "       'Prior_Conviction_Episodes_PPViolationCharges',\n",
              "       'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
              "       'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole',\n",
              "       'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed',\n",
              "       'Condition_Other', 'Violations_ElectronicMonitoring',\n",
              "       'Violations_Instruction', 'Violations_FailToReport',\n",
              "       'Violations_MoveWithoutPermission', 'Delinquency_Reports',\n",
              "       'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes',\n",
              "       'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive',\n",
              "       'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive',\n",
              "       'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year',\n",
              "       'Employment_Exempt', 'Recidivism_Arrest'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has lots of features, many of which are categorical (strings rather than numbers). In addition, many rows have one or more missing values (`NaN`). We need to address these issues, but since we have so many features, we can't look at each feature individually and determine the best approach like we did in prior problem sets. Instead, we're going to manage this automatically. It might not be as good thinking carefully about each feature, but it will get our data into a state where we can do some prediction.\n",
        "\n",
        "First, let's fill in the missing values. The code below will fill in all missing values with the mode for that column for categorical variables.\n",
        "\n",
        "As the StatQuest guy would say \"Terminology Alert!\" Filling in missing values with the mode, mean, or median is called *imputing*.\n",
        "\n",
        "Run the code below."
      ],
      "metadata": {
        "id": "w6XwUzJVeMKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify all the columns in the dataset that have NaN (missing) values\n",
        "columns_with_missing = recidivism.columns[recidivism.isnull().any()].tolist()\n",
        "\n",
        "# Replace all NaN with the mode for that column.\n",
        "for col in columns_with_missing:\n",
        "  recidivism[col].fillna(recidivism[col].mode(), inplace=True)\n",
        "\n",
        "\n",
        "## Now do the same for the test data\n",
        "columns_with_missing = test_data.columns[test_data.isnull().any()].tolist()\n",
        "for col in columns_with_missing:\n",
        "  test_data[col].fillna(test_data[col].mode(), inplace=True)\n"
      ],
      "metadata": {
        "id": "nS5RX2G9eLfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next let's replace all categorical values (like ethnicity or gender) with integer labels (1/0). Run the code below."
      ],
      "metadata": {
        "id": "HPTYS5rohRW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace categorical values in the dataset with integer labels.\n",
        "\n",
        "# First create a list of columns that can't be interpreted as numbers.\n",
        "string_columns = []\n",
        "for col in recidivism.columns:\n",
        "\n",
        "    # If all values can be converted to numeric without errors,\n",
        "    # consider it as a numeric column.\n",
        "    if recidivism[col].apply(pd.to_numeric, errors='coerce').notna().all():\n",
        "        continue\n",
        "\n",
        "    # Otherwise it's a string (categorical) column,\n",
        "    string_columns.append(col)\n",
        "\n",
        "# Next, factorize all the string (categorical) columns so\n",
        "# that the categories are represented with integers and not strings.\n",
        "for col in string_columns:\n",
        "    recidivism[col] = pd.factorize(recidivism[col])[0]\n",
        "\n",
        "\n",
        "# Now do the same for the test data\n",
        "string_columns = []\n",
        "for col in test_data.columns:\n",
        "    if test_data[col].apply(pd.to_numeric, errors='coerce').notna().all():\n",
        "        continue\n",
        "    string_columns.append(col)\n",
        "\n",
        "for col in string_columns:\n",
        "    test_data[col] = pd.factorize(test_data[col])[0]\n"
      ],
      "metadata": {
        "id": "3IccVAZDhdt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll actually create the `X` and `y`. Run this code cell, but read the comments carefully."
      ],
      "metadata": {
        "id": "4bfxU-iALMQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training dataset from the dataframe\n",
        "\n",
        "# This pulls out all the columns that are features for each sample\n",
        "# (excludes the first which is the ID and the last which is the y variable.\n",
        "X = recidivism.iloc[:, 1:-1]\n",
        "\n",
        "# This pulls out the final column which is what we are trying to predict:\n",
        "# whether or not they were arrested for a new crime upon release.\n",
        "y = recidivism[\"Recidivism_Arrest\"].ravel()\n",
        "\n",
        "\n",
        "# Create the test set from the test_data dataframe\n",
        "# Get everything but the first column, which is the ID.\n",
        "# There is no \"Recidivism_Arrest\" column because only the\n",
        "# TAs and I know the answers to the test data.\n",
        "X_test = test_data.iloc[:, 1:]"
      ],
      "metadata": {
        "id": "CL8vBABiVKhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Develop your models\n",
        "\n",
        "In this section you will run lots of experiments to try to improve upon the strongest of three baselines, the majority class baseline. As in the hackathon, you can change the parameters, features, and the models themselves. In the code spaces below you will run your experiments using k-fold cross validation. When you have three models that outperform the majority class baseline, you will proceed to step 3 and retrain those models on all the data and test on the test data. Instructions for that part of the assignment are found in step 3.\n",
        "\n",
        "**Please note: you are permitted to come up with one hand-designed method for predicting recidivism that does not use machine learning. Remember that we did this in one of the very first problem sets in the class! This will fun, and you might find that your non-machine learning method outperforms other methods.**\n",
        "\n",
        "### Demonstration of k-fold cross validation\n",
        "\n",
        "Instead of partitioning the data into a train and dev set, we are going to use 10-fold cross-validation. The code below demonstrates how to do this with three classifiers: (1) random baseline; (2) majority baseline; (3) `DecisionTreeClassifier` with default parameters.\n",
        "\n",
        "You'll see that the majority class baseline (i.e., predict that everyone does not committ a crime when they are released) outperforms the decision tree.\n",
        "\n",
        "Run the code below, then in the followin code cells run your own experiments using cross validation by selecting new algorithsm, modifying the parameters, and using more or fewer features."
      ],
      "metadata": {
        "id": "4JhZqY1cLfph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DO NOT DELETE OR MODIFY THIS CODE CELL\n",
        "## USE THIS AS A REFERENCE FOR THE CODE YOU CREATE\n",
        "## IN THE FOLLOWING CODE CELLS\n",
        "\n",
        "## DEMONSTRATION OF HOW TO USE K-FOLD CROSS-VALIDATION\n",
        "## WITH OUR THREE BASELINES\n",
        "\n",
        "# import cross validation function and classifiers\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# set the value of k\n",
        "k = 10\n",
        "\n",
        "### Random baseline\n",
        "print(\"Random baseline\")\n",
        "random_clf = DummyClassifier(strategy='uniform')\n",
        "\n",
        "# Do the cross validation\n",
        "scores = cross_val_score(random_clf, X, y, cv=k)\n",
        "\n",
        "# Then print the average of all k of those scores.\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### Majority class baseline\n",
        "print(\"Majority class baseline\")\n",
        "majority_clf = DummyClassifier(strategy='most_frequent')\n",
        "scores = cross_val_score(majority_clf, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### Decision tree classifier\n",
        "print(\"Decision tree classifier\")\n",
        "dectree = DecisionTreeClassifier()\n",
        "scores = cross_val_score(dectree, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n"
      ],
      "metadata": {
        "id": "BJ8z1H14Vhz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc817b2-920b-43e2-f80f-35e94820c94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random baseline\n",
            "Mean Accuracy: 0.5011\n",
            "\n",
            "Majority class baseline\n",
            "Mean Accuracy: 0.6023\n",
            "\n",
            "Decision tree classifier\n",
            "Mean Accuracy: 0.5736\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USE THESE CODE CELLS TO EXPERIMENT\n",
        "#increasing k by 2 fold makes it slightly more accurate\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "### Random Forest Classifier\n",
        "print(\"Random Forest classifier\")\n",
        "model1 = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=1)\n",
        "scores = cross_val_score(model1, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "ElmnJDsWRxMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b29eb8-aaa1-4770-d46a-970c3aaa76d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest classifier\n",
            "Mean Accuracy: 0.6527\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USE THESE CODE CELLS TO EXPERIMENT\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "k = 20\n",
        "\n",
        "### Ridge Classifier\n",
        "print(\"Ridge Classifier\")\n",
        "model2 = RidgeClassifier()\n",
        "scores = cross_val_score(model2, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "5z4LFs08RxVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76736496-fbfb-406d-8317-4038c4f623a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Classifier\n",
            "Mean Accuracy: 0.6520\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# USE THESE CODE CELLS TO EXPERIMENT\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "### GaussianNB\n",
        "print(\"GaussianNB\")\n",
        "model3 = GaussianNB()\n",
        "scores = cross_val_score(model3, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "qc-RClBBR9Qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421de437-6961-48f6-cd70-52d1d67b1ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GaussianNB\n",
            "Mean Accuracy: 0.6137\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THE CODE FOR YOUR FIRST BEST MODEL GOES HERE\n",
        "# Make sure to show the accuracy of your model with k-fold\n",
        "# cross-validation, as I demonstrated above.\n",
        "\n",
        "#increasing k by 2 fold makes it slightly more accurate\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "k = 20\n",
        "\n",
        "### Random baseline\n",
        "print(\"Random baseline\")\n",
        "random_clf = DummyClassifier(strategy='uniform')\n",
        "\n",
        "# Do the cross validation\n",
        "scores = cross_val_score(random_clf, X, y, cv=k)\n",
        "\n",
        "# Then print the average of all k of those scores.\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### Majority class baseline\n",
        "print(\"Majority class baseline\")\n",
        "majority_clf = DummyClassifier(strategy='most_frequent')\n",
        "scores = cross_val_score(majority_clf, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### Random Forest Classifier\n",
        "print(\"Random Forest classifier\")\n",
        "model1 = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=1)\n",
        "scores = cross_val_score(model1, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "BSOcsVt9Rxdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac38590-f739-4110-ea1d-2beef6ccc18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random baseline\n",
            "Mean Accuracy: 0.4945\n",
            "\n",
            "Majority class baseline\n",
            "Mean Accuracy: 0.6023\n",
            "\n",
            "Random Forest classifier\n",
            "Mean Accuracy: 0.6527\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THE CODE FOR YOUR SECOND BEST MODEL GOES HERE\n",
        "# Make sure to show the accuracy of your model with k-fold\n",
        "# cross-validation, as I demonstrated above.\n",
        "\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "k = 20\n",
        "\n",
        "### Random baseline\n",
        "print(\"Random baseline\")\n",
        "random_clf = DummyClassifier(strategy='uniform')\n",
        "\n",
        "# Do the cross validation\n",
        "scores = cross_val_score(random_clf, X, y, cv=k)\n",
        "\n",
        "# Then print the average of all k of those scores.\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### Majority class baseline\n",
        "print(\"Majority class baseline\")\n",
        "majority_clf = DummyClassifier(strategy='most_frequent')\n",
        "scores = cross_val_score(majority_clf, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### Ridge Classifier\n",
        "print(\"Ridge Classifier\")\n",
        "model2 = RidgeClassifier()\n",
        "scores = cross_val_score(model2, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "tEInjYW1Rxjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bedd103d-542b-46fe-cc3c-b27fdcdb28f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random baseline\n",
            "Mean Accuracy: 0.5021\n",
            "\n",
            "Majority class baseline\n",
            "Mean Accuracy: 0.6023\n",
            "\n",
            "Ridge Classifier\n",
            "Mean Accuracy: 0.6520\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THE CODE FOR YOUR THIRD BEST MODEL GOES HERE\n",
        "# Make sure to show the accuracy of your model with k-fold\n",
        "# cross-validation, as I demonstrated above.\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "k = 20\n",
        "\n",
        "### Random baseline\n",
        "print(\"Random baseline\")\n",
        "random_clf = DummyClassifier(strategy='uniform')\n",
        "\n",
        "# Do the cross validation\n",
        "scores = cross_val_score(random_clf, X, y, cv=k)\n",
        "\n",
        "# Then print the average of all k of those scores.\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### Majority class baseline\n",
        "print(\"Majority class baseline\")\n",
        "majority_clf = DummyClassifier(strategy='most_frequent')\n",
        "scores = cross_val_score(majority_clf, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()\n",
        "\n",
        "### GaussianNB\n",
        "print(\"GaussianNB Classifier\")\n",
        "model3 = GaussianNB()\n",
        "scores = cross_val_score(model3, X, y, cv=k)\n",
        "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "My7nkv02RxpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ccd78b-06ea-4369-ad99-2e3f4ad00c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random baseline\n",
            "Mean Accuracy: 0.4982\n",
            "\n",
            "Majority class baseline\n",
            "Mean Accuracy: 0.6023\n",
            "\n",
            "GaussianNB Classifier\n",
            "Mean Accuracy: 0.6137\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create your submissions\n",
        "\n",
        "Above you experiments and found three models that outperform the majority class baseline under 10-fold cross-validation. Now you need to train those models on *all* the data and test them on the official test data from `test.csv`.\n",
        "\n",
        "Above I carefully read in `test.csv` into a variable called `X_test`. If you have not modified the features in any way, you can use `X`, `y`, and `X_test` as is, as I show below.\n",
        "\n",
        "\n",
        "### If you changed the features...\n",
        "**If you  modified the features** in your experiments above (e.g., you are using fewer features, you altered the feature values somehow), you will need to make those modifications to `X` and `X_test` in the code cell below.\n",
        "\n",
        "If you did not change the features, you can skip this code cell.\n",
        "\n"
      ],
      "metadata": {
        "id": "xRdM_3kxNFWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Here ia a code cell where you can adjust the feautres for X and X_test\n",
        "## in case that was something you did in your experiments above that resulted\n",
        "## in a better model.\n",
        "\n",
        "## If you did not change the features, you do not need to write anything in\n",
        "## this cell.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q3gRoxsaQVUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Demonstration of creating your submissions\n",
        "\n",
        "Above we did cross validation to evaluate three naive models. The code below creates one submission for each of these models trained on the *full* dataset and tested on the `test.csv` data.\n",
        "\n",
        "You will edit these codes cells to create your submissions from your strongest models. You will just have to replace the lines initializing the models with the line you used in your cross-validation experiment to initialize your strong-performing model.\n",
        "\n",
        "**AGAIN:** In the code below you will replace the models with the ones you created. You don't need to make any other changes. If you changed the features, please include that code in the above code cell, as clearly indicated."
      ],
      "metadata": {
        "id": "dPi-rQj2Szf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "## My submission #1: random forest classifier\n",
        "\n",
        "## Change the line below to create your model.\n",
        "## If you changed features and created new variables, replace X,\n",
        "## y, and X_test to your new variables.\n",
        "\n",
        "model1 = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=1)\n",
        "\n",
        "model1.fit(X, y)\n",
        "y_pred_random = model1.predict(X_test)\n",
        "with open(\"submission1.csv\", 'w', newline='') as f:\n",
        "    for e in y_pred_random:\n",
        "      f.write(str(e) + \"\\n\")"
      ],
      "metadata": {
        "id": "T3KjQ0uUT2IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## My submission #2: ridge classifier\n",
        "\n",
        "model2 = RidgeClassifier()\n",
        "model2.fit(X, y)\n",
        "y_pred_ridge = model2.predict(X_test)\n",
        "with open(\"submission2.csv\", 'w', newline='') as f:\n",
        "    for e in y_pred_ridge:\n",
        "      f.write(str(e) + \"\\n\")"
      ],
      "metadata": {
        "id": "-WHqxfmPUDz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## My submission #3: Gaussian NB classifier\n",
        "\n",
        "model3 = GaussianNB()\n",
        "model3.fit(X, y)\n",
        "y_pred_gauss = model3.predict(X_test)\n",
        "with open(\"submission3.csv\", 'w', newline='') as f:\n",
        "    for e in y_pred_gauss:\n",
        "      f.write(str(e) + \"\\n\")"
      ],
      "metadata": {
        "id": "KTlBW8l7UeBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving your submissions to your Google Drive\n",
        "\n",
        "Now you need to mount your Google Drive, create a folder there, and move your submissions to that folder. When you log into drive.google.com, you will see that folder. You will share that folder with the TAs just as you always do with Colab notebooks, and you will also download the files to your computer and commit them to your GitHub repo.\n",
        "\n",
        "The first step is to mount your Google Drive. This will open a dialog window. Just keep clicking yes. You are just giving Google permission to look at your Drive from Colab, which Google also owns."
      ],
      "metadata": {
        "id": "pcFnhgV6VhrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "8lyECYrJVd9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9942dd94-3b30-461a-8996-9d385606a6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block below creates a folder in your drive called `problemset10` then moves your submission CSVs to that folder in your Drive. The final line should list your three submission CSVs.\n",
        "\n",
        "You must run this code every time you create a new submission CSV file.\n",
        "\n",
        "After you run this code, you can go to [drive.google.com](https://drive.google.com/drive/u/0/my-drive) and you'll see your `problemset10` folder."
      ],
      "metadata": {
        "id": "CtXkykO7W6ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/problemset10\n",
        "!mv submission* /content/drive/MyDrive/problemset10\n",
        "!ls /content/drive/MyDrive/problemset10"
      ],
      "metadata": {
        "id": "ITcCyqpEWKk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237faba5-667c-4cd9-cfe2-10bd4c5c035c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission1.csv  submission2.csv  submission3.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## How to submit\n",
        "\n",
        "1. Share this Colab notebook with the TAs and me.\n",
        "2. Share your `problemset10` folder with the TAs and me.\n",
        "3. Download the Colab notebook and push it to your GitHub repo.\n",
        "4. Download your submissions and push them to your GitHub repo.\n",
        "\n",
        "**This problem set is due Thursday, May 2, at 11:59pm.**\n",
        "\n",
        "You have a 24-hour grace period. I don't want to make any work actually due after the end of classes, but you may submit the problem set on Friday if you prefer."
      ],
      "metadata": {
        "id": "U5qbjbyeXQvi"
      }
    }
  ]
}